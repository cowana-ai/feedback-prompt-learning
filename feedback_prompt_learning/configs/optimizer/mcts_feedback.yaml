# MCTS Optimizer Configuration with Feedback-based prompts

# MCTS-specific parameters
num_iterations: 12
exploration_constant: 2.5
minibatch_size_train: 5
minibatch_size_eval: 40
max_depth: 8
expand_width: 3
num_samples: 1
post_instruction: false

llm:
  student:
    _target_: langchain_openai.ChatOpenAI
    model_name: gpt-4o-mini
    temperature: 0.
  action:
    _target_: langchain_openai.ChatOpenAI
    model_name: gpt-4o
    temperature: 0.
  critic:
    _target_: langchain_openai.ChatOpenAI
    model_name: gpt-4o
    temperature: 1.

sample_examples:
  num_historical: 5

# Example formatting templates
example_format:
  header: "Total evaluations: {total}\nShowing {shown} evaluated examples:\n"

  with_feedback: |

    Example {index} (Score: {score:.2f}):
    Question: {input}
    LLM Output: {output}
    Expected: {target}
    Accuracy Feedback: {accuracy_feedback}
    Reasoning Feedback: {reasoning_feedback}

  without_feedback: |

    Example {index} (Score: {score:.2f}):
    Question: {input}
    LLM Output: {output}
    Expected: {target}

# Prompts for gradient analysis and optimization
gradient_analysis_prompt: |
  I'm writing prompts for a smaller language model designed for a task.

  My current prompt is:
  {prompt}

  {example_string_with_feedback}

  Average Score across all evaluations: {avg_score:.2f}

  For each wrong example, let's first understand the problem and devise a plan to solve the problem. Carefully analyze each example and understand the errors in the response or reasoning based on the reasoning & prompt feedback and score provided.
  As a teacher model, analyze the errors systematically (pay attention to specific failure patterns and feedback themes), diagnose the root causes step by step. At last, based on all these reasons, summarize and list all the aspects that can improve the prompt by providing a structured response:
  Prompt analysis (based on prompt feedback):
  <your analysis>
  Reasoning and diagnosis (based on error patterns and reasoning feedback):
  <your reasoning>
  Finally, what should be improved in the prompt:
  <final list of aspects to improve the prompt>

prompt_generation_prompt: |
  I'm writing prompts for a language model designed for a task.

  My current prompt is:
  {current_prompt}

  {example_string}

  Based on the prompt errors, the problems with this prompt and the proposed solutions are:
  {gradient}

  There is a list of former prompts including the current prompt, and each prompt is modified from its former prompts:
  {trajectory_text}

  Based on the above information, please write {num_prompts} new prompt{plural} following these guidelines:
  1. The new prompt should solve the current prompt's problems identified in the gradient analysis.
  2. The new prompt should consider the list of prompts and evolve based on the current prompt.
  3. Each new prompt should be wrapped with <START> and <END> tags.
  The new prompt{plural_verb}:
