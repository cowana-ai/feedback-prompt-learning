# Dataset configurations for BigBench tasks
# Centralized configuration to avoid hardcoding paths

datasets:
  penguins:
    name: "penguins_in_a_table"
    description: "Answer questions about a table of penguins and their attributes"
    data_path: "dataset/penguins_in_a_table.json"
    init_prompt: "Answer questions about a table of penguins and their attributes."
    train_size: 70
    eval_size: 70
    test_size: 79
    seed: 42
    post_instruction: false  # Question before prompt

  geometric_shapes:
    name: "geometric_shapes"
    description: "Name geometric shapes from their SVG paths"
    data_path: "dataset/geometric_shapes.json"
    init_prompt: "Identify the geometric shape from the SVG path element."
    train_size: 150
    eval_size: 150
    test_size: 200
    seed: 42
    post_instruction: false

  epistemic:
    name: "epistemic"
    description: "Determine whether one sentence entails the next"
    data_path: "dataset/epistemic.json"
    init_prompt: "Determine whether one sentence entails the next."
    train_size: 300
    eval_size: 200
    test_size: 500
    seed: 42
    post_instruction: false

  object_counting:
    name: "object_counting"
    description: "Questions that involve enumerating objects of different types and asking the model to count them"
    data_path: "dataset/object_counting.json"
    init_prompt: "Count the overall number of all items."
    train_size: 150
    eval_size: 150
    test_size: 500
    seed: 42
    post_instruction: false

  casual_judgement:
    name: "causal_judgment"
    description: "Answer questions about causal attribution"
    data_path: "dataset/casual_judgement.json"
    init_prompt: "Answer questions about causal attribution."
    train_size: 90
    eval_size: 90
    test_size: 100
    seed: 42
    post_instruction: false
